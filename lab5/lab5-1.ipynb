{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-05T20:22:30.436831Z","iopub.execute_input":"2022-01-05T20:22:30.437115Z","iopub.status.idle":"2022-01-05T20:22:30.441366Z","shell.execute_reply.started":"2022-01-05T20:22:30.437084Z","shell.execute_reply":"2022-01-05T20:22:30.440469Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#configuration\nbatch_size = 64 \nepochs = 100 \nlatent_dim = 256\nnum_samples = 10000\n#file from http://www.manythings.org/anki\ndata_path = \"../input/nldeng/nld.txt\"","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:22:41.813540Z","iopub.execute_input":"2022-01-05T20:22:41.813829Z","iopub.status.idle":"2022-01-05T20:22:41.819352Z","shell.execute_reply.started":"2022-01-05T20:22:41.813798Z","shell.execute_reply":"2022-01-05T20:22:41.818441Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"input_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\n\nwith open(data_path, \"r\", encoding=\"utf-8\") as f:\n    lines = f.read().split(\"\\n\")\n\nfor line in lines[: min(num_samples, len(lines) - 1)]:\n    input_text, target_text, _ = line.split(\"\\t\")\n    target_text = \"\\t\" + target_text + \"\\n\"\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    for char in input_text:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in target_text:\n        if char not in target_characters:\n            target_characters.add(char)\n\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\n\ninput_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\ntarget_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n\nencoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\ndecoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\ndecoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n\nfor i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1.0\n    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n    for t, char in enumerate(target_text):\n        decoder_input_data[i, t, target_token_index[char]] = 1.0\n        if t > 0:\n            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:22:45.607036Z","iopub.execute_input":"2022-01-05T20:22:45.607705Z","iopub.status.idle":"2022-01-05T20:22:46.467996Z","shell.execute_reply.started":"2022-01-05T20:22:45.607646Z","shell.execute_reply":"2022-01-05T20:22:46.467164Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\nencoder = keras.layers.LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\nencoder_states = [state_h, state_c]\n\ndecoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\ndecoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\ndecoder_outputs = decoder_dense(decoder_outputs)\n\nmodel = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:22:50.306559Z","iopub.execute_input":"2022-01-05T20:22:50.306854Z","iopub.status.idle":"2022-01-05T20:22:50.809189Z","shell.execute_reply.started":"2022-01-05T20:22:50.306826Z","shell.execute_reply":"2022-01-05T20:22:50.808389Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2, )\nmodel.save(\"s2s\")","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:22:53.295397Z","iopub.execute_input":"2022-01-05T20:22:53.296157Z","iopub.status.idle":"2022-01-05T21:06:58.077604Z","shell.execute_reply.started":"2022-01-05T20:22:53.296103Z","shell.execute_reply":"2022-01-05T21:06:58.076791Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(\"s2s\")\n\nencoder_inputs = model.input[0]  # input_1\nencoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\nencoder_states = [state_h_enc, state_c_enc]\nencoder_model = keras.Model(encoder_inputs, encoder_states)\n\ndecoder_inputs = model.input[1]  # input_2\ndecoder_state_input_h = keras.Input(shape=(latent_dim,))\ndecoder_state_input_c = keras.Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_lstm = model.layers[3]\ndecoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs\n)\ndecoder_states = [state_h_dec, state_c_dec]\ndecoder_dense = model.layers[4]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = keras.Model(\n    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n)\n\nreverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n\n\ndef decode_sequence(input_seq):\n    states_value = encoder_model.predict(input_seq)\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n    stop_condition = False\n    decoded_sentence = \"\"\n    \n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n            stop_condition = True\n\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.0\n\n        states_value = [h, c]\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2022-01-05T21:09:40.713557Z","iopub.execute_input":"2022-01-05T21:09:40.713869Z","iopub.status.idle":"2022-01-05T21:09:45.426446Z","shell.execute_reply.started":"2022-01-05T21:09:40.713835Z","shell.execute_reply":"2022-01-05T21:09:45.425649Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"for seq_index in range(25):\n    input_seq = encoder_input_data[seq_index : seq_index + 1]\n    decoded_sentence = decode_sequence(input_seq)\n    print(\"-\")\n    print(\"Input sentence:\", input_texts[seq_index])\n    print(\"Decoded sentence:\", decoded_sentence)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T21:10:19.733995Z","iopub.execute_input":"2022-01-05T21:10:19.734284Z","iopub.status.idle":"2022-01-05T21:10:33.142421Z","shell.execute_reply.started":"2022-01-05T21:10:19.734251Z","shell.execute_reply":"2022-01-05T21:10:33.141559Z"},"trusted":true},"execution_count":24,"outputs":[]}]}